{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzA1-mt88AO_"
      },
      "source": [
        "# StyleGAN2-ada operations\n",
        "\n",
        "### Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IFfx8GQIAQm"
      },
      "source": [
        "\n",
        "**Run this cell after each session restart**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkbcraCUaPEy",
        "outputId": "44ea3003-c85d-4e9c-944a-8ee2dffb25e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.7.1 in /usr/local/lib/python3.7/dist-packages (1.7.1)\n",
            "Requirement already satisfied: torchvision==0.8.2 in /usr/local/lib/python3.7/dist-packages (0.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2) (7.1.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.7/dist-packages (1.10.2.3)\n",
            "Mounted at /G\n",
            "/G/MyDrive\n",
            "/G/MyDrive/sg2a_eps\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (7.1.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (5.4.8)\n",
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=bffd82cda0ef2ca409246a6f4b7cea514660695cd650c9ce8a5fe853c47bcee0\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-6f623240-71fc-dc6f-d77a-aa02946f51fb)\n",
            "GPU RAM 16280MB | Free 16280MB)\n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "#@title General setup { display-mode: \"form\", run: \"auto\" }\n",
        "\n",
        "!pip install torch==1.7.1 torchvision==0.8.2\n",
        "\n",
        "from IPython.display import HTML, Image, display\n",
        "from moviepy.editor import ImageSequenceClip, ipython_display\n",
        "import ipywidgets as widgets\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "!apt-get -qq install ffmpeg\n",
        "!pip install ninja\n",
        "from google.colab import drive\n",
        "drive.mount('/G', force_remount=True)\n",
        "gdir = '/G/MyDrive/'\n",
        "%cd $gdir\n",
        "\n",
        "#@markdown Copying StyleGAN2 to the directory below on your Google drive (creating it, if it doesn't exist):\n",
        "work_dir = 'sg2a_eps' #@param {type:\"string\"}\n",
        "#@markdown NB: All paths below are relative to this directory (except the archive with source images on the next step). \n",
        "\n",
        "#@markdown NB: Avoid connecting Google drive manually via the icon in Files section on the left. Doing so may break further operations.\n",
        "\n",
        "work_dir = gdir + work_dir + '/'\n",
        "if not os.path.isdir(work_dir):\n",
        "  !git clone git://github.com/eps696/stylegan2ada $work_dir\n",
        "%cd $work_dir\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "from src.util.utilgan import file_list, img_list, basename\n",
        "model = model_pkl = ''\n",
        "def model_select(work_dir):\n",
        "  models = file_list(work_dir, 'pkl', subdir=True)\n",
        "  global model, model_pkl\n",
        "  model_pkl = models[0]\n",
        "  model = model_pkl.replace('.pkl', '')\n",
        "  models = [m.replace(work_dir, '') for m in models if not basename(m) in ['submit_config', 'vgg16_zhang_perceptual']]\n",
        "  def on_change(change):\n",
        "    global model, model_pkl\n",
        "    if change['type'] == 'change' and change['name'] == 'value':\n",
        "      model = change['new']\n",
        "      model = os.path.splitext(model)[0] # filename without extension => load custom network\n",
        "      model_pkl = model + '.pkl' # filename with extension => load original network\n",
        "  model_select = widgets.Dropdown(options=models, description='Found models:', style={'description_width': 'initial'}, layout={'width': 'max-content'})\n",
        "  display(model_select)\n",
        "  model_select.observe(on_change)\n",
        "# model_select(work_dir)\n",
        "\n",
        "# Hardware check\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil \n",
        "import GPUtil as GPU\n",
        "gpu = GPU.getGPUs()[0]\n",
        "!nvidia-smi -L\n",
        "print(\"GPU RAM {0:.0f}MB | Free {1:.0f}MB)\".format(gpu.memoryTotal, gpu.memoryFree))\n",
        "print('\\nDone!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWpWFeyO8APF"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_LGhTfV8APG"
      },
      "source": [
        "First, let's prepare the dataset. Ensure all your images have the same color channels (monochrome, RGB or RGBA). If you edit the images yourself (e.g. for non-square aspect ratios, or to keep the compositions), ensure their correct size.  \n",
        "For conditional model the images should be split by subfolders (mydata/1, mydata/2, ..).\n",
        "\n",
        "Upload zip-archive with images onto Google drive and type its path here (relative to G-drive root). \n",
        "\n",
        "If you work with patterns or shapes (rather than compostions), you may want to enable `multicrop` to crop square fragments from bigger images, effectively increasing amount of data (not suitable for conditional data, as it would break folder structure!). The images will be cut into `size`px fragments, overlapped with `step` shift by X and Y. If the image is smaller, it will be upscaled to the `size`. Edit these values according to your dataset.   \n",
        "*Restart session (Runtime) after `multicrop` run*. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEmNzQmm0t_o",
        "outputId": "ddde3dbe-32a1-4811-c18e-664887ea1c04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/tmp\n",
            "/G/MyDrive/sg2a_eps\n"
          ]
        }
      ],
      "source": [
        "#@title Data setup \n",
        "dataset = 'test' #@param {type:\"string\"}\n",
        "source = 'source.zip' #@param {type:\"string\"}\n",
        "content_data = os.path.join('/content', dataset)\n",
        "data_dir = os.path.join(work_dir, 'data/')\n",
        "dataset_dir = os.path.join(data_dir, dataset)\n",
        "\n",
        "#@markdown Multicrop\n",
        "multicrop = False  #@param {type:\"boolean\"}\n",
        "size = \"512\" #@param [256,512,1024]\n",
        "overlap = 128 #@param {type:\"integer\"}\n",
        "size = int(size)\n",
        "\n",
        "# cleanup previous attempts\n",
        "!rm -rf /content/tmp \n",
        "!rm -rf $content_data\n",
        "!rm -rf $dataset_dir\n",
        "\n",
        "!mkdir /content/tmp\n",
        "%cd /content/tmp\n",
        "fpath = os.path.join(gdir, source)\n",
        "!unzip -o -q $fpath -d $dataset\n",
        "%cd $work_dir\n",
        "\n",
        "if multicrop:\n",
        "  if os.path.isdir('/content/tmp'):\n",
        "    %run src/util/multicrop.py --in_dir /content/tmp --out_dir $content_data --size $size --step $overlap\n",
        "    !mv $content_data $data_dir\n",
        "  else:\n",
        "    print('/content/tmp not found!!')\n",
        "else:\n",
        "  !mv /content/tmp/* $data_dir\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfczVF0W8APH"
      },
      "source": [
        "Now, we can train StyleGAN2 on the prepared dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YKmktOPb8APH"
      },
      "outputs": [],
      "source": [
        "#@title Train\n",
        "%cd $work_dir\n",
        "dataset = 'test' #@param {type:\"string\"}\n",
        "kimg = 5000 #@param {type:\"integer\"}\n",
        "data_dir = os.path.join(work_dir, 'data', dataset)\n",
        "\n",
        "%run src/train.py --data $data_dir --kimg $kimg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYlI1fXe8APH"
      },
      "source": [
        "> This will run training process, according to the options and settings in `src/train.py` (check and explore those!!). Results (models and samples) are saved under `train` directory, similar to original Nvidia approach. There are two types of models saved: compact (containing only Gs network for inference) as `<dataset>-...pkl` (e.g. `test-256-0360.pkl`), and full (containing G/D/Gs networks for further training) as `snapshot-...pkl`. Check sample images there to follow the progress.\n",
        "\n",
        "> The length of the training is defined by `--kimg X` argument (training duration in thousands of images). Reasonable `kimg` value for full training from scratch is 5000-8000, while for finetuning in `--d_aug` mode 1000-2000 may be sufficient.  \n",
        "\n",
        "> *NB: If you get `RuntimeError: context has already been set` (e.g. after training interruption or `multicrop` run) - restart session, run General setup and Train again.*\n",
        "\n",
        "Other training options:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAqpEFzukpfs"
      },
      "outputs": [],
      "source": [
        "%run src/train.py --help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpeUmhiH8API"
      },
      "source": [
        "If the training process was interrupted, resume it from the last saved model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr73IUPG8API",
        "outputId": "e6041a4f-0439-47ec-88be-422283ae0162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/G/MyDrive/sg2a_eps\n",
            " Dataset subdirs are set for labels\n",
            " Train dir:  train/007-test-512-auto-gf_bnc\n",
            " Dataset:    /G/MyDrive/sg2a_eps/data/test\n",
            " Resolution: 512\n",
            " Batch:      8\n",
            " Length:     5000 kimg\n",
            " Augment:    gf_bnc\n",
            " Num images: 1478 (+mirror)\n",
            "Image shape: [3, 512, 512]\n",
            "Label shape: [0]\n",
            "Constructing networks...\n",
            " Resuming from \"train/006-test-512-auto-gf_bnc/snapshot-512-0300.pkl\", kimg 300\n",
            "Training for 5000 kimg...\n",
            "\n",
            "tick 0    kimg 0.0    time 1m 16s    376d 16:55:38s left till 14:28  min/tick 0.868  sec/kimg 6.51e+03 cpumem 3.3  gpumem 13.2 aug 0.000 lr 0.0025 0.0025\n",
            "tick 1    kimg 4.0    time 18m 25s   14d 19:45:45s left till 17:35  min/tick 17.1   sec/kimg 256     cpumem 4.0  gpumem 7.3  aug 0.034 lr 0.0025 0.0025\n",
            "tick 2    kimg 8.0    time 35m 31s   14d 19:45:32s left till 17:52  min/tick 17.1   sec/kimg 257     cpumem 4.0  gpumem 7.4  aug 0.067 lr 0.0025 0.0025\n",
            "tick 3    kimg 12.0   time 52m 38s   14d 19:38:08s left till 18:02  min/tick 17.1   sec/kimg 257     cpumem 4.0  gpumem 7.3  aug 0.098 lr 0.0025 0.0025\n",
            "tick 4    kimg 16.0   time 1h 09m 47s  14d 19:47:59s left till 18:29  min/tick 17.1   sec/kimg 257     cpumem 4.0  gpumem 7.4  aug 0.129 lr 0.0025 0.0025\n",
            "tick 5    kimg 20.0   time 1h 26m 55s  14d 19:20:38s left till 18:19  min/tick 17.1   sec/kimg 257     cpumem 4.0  gpumem 7.4  aug 0.162 lr 0.0025 0.0025\n",
            "tick 6    kimg 24.0   time 1h 44m 05s  14d 19:14:42s left till 18:30  min/tick 17.1   sec/kimg 257     cpumem 4.0  gpumem 7.5  aug 0.192 lr 0.0025 0.0025\n",
            "tick 7    kimg 28.0   time 2h 01m 14s  14d 19:01:16s left till 18:34  min/tick 17.1   sec/kimg 257     cpumem 4.0  gpumem 7.4  aug 0.220 lr 0.0025 0.0025\n",
            "tick 8    kimg 32.0   time 2h 18m 23s  14d 19:07:25s left till 18:57  min/tick 17.2   sec/kimg 257     cpumem 4.0  gpumem 7.4  aug 0.247 lr 0.0025 0.0025\n",
            "tick 9    kimg 36.0   time 2h 35m 33s  14d 18:38:15s left till 18:45  min/tick 17.1   sec/kimg 257     cpumem 4.0  gpumem 7.5  aug 0.271 lr 0.0025 0.0025\n",
            "tick 10   kimg 40.0   time 2h 52m 42s  14d 18:26:36s left till 18:50  min/tick 17.2   sec/kimg 257     cpumem 4.0  gpumem 7.4  aug 0.298 lr 0.0025 0.0025\n",
            "tick 11   kimg 44.0   time 3h 09m 54s  14d 18:16:40s left till 18:58  min/tick 17.2   sec/kimg 257     cpumem 4.0  gpumem 7.5  aug 0.324 lr 0.0025 0.0025\n",
            "tick 12   kimg 48.0   time 3h 27m 05s  14d 18:22:07s left till 19:20  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.4  aug 0.351 lr 0.0025 0.0025\n",
            "tick 13   kimg 52.0   time 3h 44m 15s  14d 17:53:23s left till 19:09  min/tick 17.2   sec/kimg 257     cpumem 4.0  gpumem 7.4  aug 0.372 lr 0.0025 0.0025\n",
            "tick 14   kimg 56.0   time 4h 01m 25s  14d 17:36:49s left till 19:09  min/tick 17.2   sec/kimg 257     cpumem 4.0  gpumem 7.5  aug 0.395 lr 0.0025 0.0025\n",
            "tick 15   kimg 60.0   time 4h 18m 36s  14d 17:23:07s left till 19:13  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.5  aug 0.418 lr 0.0025 0.0025\n",
            "tick 16   kimg 64.0   time 4h 35m 49s  14d 17:25:14s left till 19:32  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.5  aug 0.436 lr 0.0025 0.0025\n",
            "tick 17   kimg 68.0   time 4h 53m 00s  14d 16:50:28s left till 19:15  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.5  aug 0.453 lr 0.0025 0.0025\n",
            "tick 18   kimg 72.0   time 5h 10m 11s  14d 16:36:03s left till 19:17  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.5  aug 0.475 lr 0.0025 0.0025\n",
            "tick 19   kimg 76.0   time 5h 27m 21s  14d 16:22:35s left till 19:21  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.6  aug 0.488 lr 0.0025 0.0025\n",
            "tick 20   kimg 80.0   time 5h 44m 33s  14d 16:23:57s left till 19:40  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.5  aug 0.506 lr 0.0025 0.0025\n",
            "tick 21   kimg 84.0   time 6h 01m 47s  14d 15:55:40s left till 19:29  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.5  aug 0.521 lr 0.0025 0.0025\n",
            "tick 22   kimg 88.0   time 6h 18m 58s  14d 15:39:47s left till 19:30  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.5  aug 0.538 lr 0.0025 0.0025\n",
            "tick 23   kimg 92.0   time 6h 36m 09s  14d 15:29:40s left till 19:37  min/tick 17.2   sec/kimg 258     cpumem 4.1  gpumem 7.5  aug 0.555 lr 0.0025 0.0025\n",
            "tick 24   kimg 96.0   time 6h 53m 22s  14d 15:34:29s left till 19:59  min/tick 17.2   sec/kimg 258     cpumem 4.1  gpumem 7.5  aug 0.566 lr 0.0025 0.0025\n",
            "tick 25   kimg 100.0  time 7h 10m 34s  14d 15:01:02s left till 19:43  min/tick 17.2   sec/kimg 258     cpumem 4.1  gpumem 7.6  aug 0.573 lr 0.0025 0.0025\n",
            "tick 26   kimg 104.0  time 7h 27m 48s  14d 14:38:26s left till 19:37  min/tick 17.2   sec/kimg 258     cpumem 4.1  gpumem 7.5  aug 0.586 lr 0.0025 0.0025\n",
            "tick 27   kimg 108.0  time 7h 44m 59s  14d 14:23:25s left till 19:40  min/tick 17.2   sec/kimg 258     cpumem 4.1  gpumem 7.5  aug 0.600 lr 0.0025 0.0025\n",
            "tick 28   kimg 112.0  time 8h 02m 12s  14d 14:28:13s left till 20:02  min/tick 17.2   sec/kimg 258     cpumem 4.1  gpumem 7.5  aug 0.608 lr 0.0025 0.0025\n",
            "tick 29   kimg 116.0  time 8h 19m 25s  14d 13:57:21s left till 19:48  min/tick 17.2   sec/kimg 258     cpumem 4.1  gpumem 7.5  aug 0.618 lr 0.0025 0.0025\n",
            "tick 30   kimg 120.0  time 8h 36m 37s  14d 13:42:27s left till 19:50  min/tick 17.2   sec/kimg 258     cpumem 4.1  gpumem 7.5  aug 0.631 lr 0.0025 0.0025\n",
            "tick 31   kimg 124.0  time 8h 53m 51s  14d 13:22:56s left till 19:48  min/tick 17.2   sec/kimg 258     cpumem 4.1  gpumem 7.5  aug 0.641 lr 0.0025 0.0025\n",
            "tick 32   kimg 128.0  time 9h 11m 04s  14d 13:22:12s left till 20:04  min/tick 17.2   sec/kimg 258     cpumem 4.1  gpumem 7.5  aug 0.652 lr 0.0025 0.0025\n",
            "tick 33   kimg 132.0  time 9h 28m 17s  14d 12:51:06s left till 19:51  min/tick 17.2   sec/kimg 258     cpumem 4.1  gpumem 7.6  aug 0.664 lr 0.0025 0.0025\n",
            "tick 34   kimg 136.0  time 9h 45m 29s  14d 12:35:03s left till 19:52  min/tick 17.2   sec/kimg 258     cpumem 4.1  gpumem 7.6  aug 0.667 lr 0.0025 0.0025\n",
            "tick 35   kimg 140.0  time 10h 02m 41s  14d 12:17:31s left till 19:51  min/tick 17.2   sec/kimg 258     cpumem 4.1  gpumem 7.5  aug 0.676 lr 0.0025 0.0025\n",
            "tick 36   kimg 144.0  time 10h 19m 57s  14d 12:18:40s left till 20:10  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.6  aug 0.683 lr 0.0025 0.0025\n",
            "tick 37   kimg 148.0  time 10h 37m 10s  14d 11:46:18s left till 19:55  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.6  aug 0.690 lr 0.0025 0.0025\n",
            "tick 38   kimg 152.0  time 10h 54m 22s  14d 11:28:48s left till 19:54  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.5  aug 0.698 lr 0.0025 0.0025\n",
            "tick 39   kimg 156.0  time 11h 11m 35s  14d 11:12:32s left till 19:55  min/tick 17.2   sec/kimg 258     cpumem 4.1  gpumem 7.6  aug 0.712 lr 0.0025 0.0025\n",
            "tick 40   kimg 160.0  time 11h 28m 48s  14d 11:19:07s left till 20:19  min/tick 17.2   sec/kimg 258     cpumem 4.1  gpumem 7.6  aug 0.721 lr 0.0025 0.0025\n",
            "tick 41   kimg 164.0  time 11h 46m 03s  14d 10:40:36s left till 19:58  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.5  aug 0.732 lr 0.0025 0.0025\n",
            "tick 42   kimg 168.0  time 12h 03m 16s  14d 10:33:51s left till 20:08  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.6  aug 0.738 lr 0.0025 0.0025\n",
            "tick 43   kimg 172.0  time 12h 20m 29s  14d 10:19:43s left till 20:11  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.5  aug 0.743 lr 0.0025 0.0025\n",
            "tick 44   kimg 176.0  time 12h 37m 44s  14d 10:20:49s left till 20:30  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.6  aug 0.752 lr 0.0025 0.0025\n",
            "tick 45   kimg 180.0  time 12h 54m 57s  14d 9:51:03s left till 20:17  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.6  aug 0.767 lr 0.0025 0.0025\n",
            "tick 46   kimg 184.0  time 13h 12m 13s  14d 9:34:28s left till 20:18  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.6  aug 0.775 lr 0.0025 0.0025\n",
            "tick 47   kimg 188.0  time 13h 29m 27s  14d 9:18:15s left till 20:19  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.6  aug 0.780 lr 0.0025 0.0025\n",
            "tick 48   kimg 192.0  time 13h 46m 41s  14d 9:20:46s left till 20:39  min/tick 17.2   sec/kimg 259     cpumem 4.0  gpumem 7.6  aug 0.787 lr 0.0025 0.0025\n",
            "tick 49   kimg 196.0  time 14h 03m 55s  14d 8:46:22s left till 20:21  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.6  aug 0.792 lr 0.0025 0.0025\n",
            "tick 50   kimg 200.0  time 14h 21m 09s  14d 8:30:42s left till 20:23  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.6  aug 0.798 lr 0.0025 0.0025\n",
            "tick 51   kimg 204.0  time 14h 38m 25s  14d 8:12:48s left till 20:22  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.6  aug 0.807 lr 0.0025 0.0025\n",
            "tick 52   kimg 208.0  time 14h 55m 40s  14d 8:12:50s left till 20:40  min/tick 17.2   sec/kimg 259     cpumem 4.0  gpumem 7.6  aug 0.816 lr 0.0025 0.0025\n",
            "tick 53   kimg 212.0  time 15h 12m 54s  14d 7:40:03s left till 20:24  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.6  aug 0.817 lr 0.0025 0.0025\n",
            "tick 54   kimg 216.0  time 15h 30m 08s  14d 7:23:29s left till 20:25  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.5  aug 0.816 lr 0.0025 0.0025\n",
            "tick 55   kimg 220.0  time 15h 47m 22s  14d 7:05:16s left till 20:24  min/tick 17.2   sec/kimg 258     cpumem 4.0  gpumem 7.6  aug 0.819 lr 0.0025 0.0025\n"
          ]
        }
      ],
      "source": [
        "#@title Resume training\n",
        "%cd $work_dir\n",
        "dataset = 'test' #@param {type:\"string\"}\n",
        "resume_dir = 'train/006-test-512-auto-gf_bnc' #@param {type:\"string\"}\n",
        "kimg = 5000 #@param {type:\"integer\"}\n",
        "data_dir = os.path.join(work_dir, 'data', dataset)\n",
        "\n",
        "%run src/train.py --data $data_dir --resume $resume_dir --kimg $kimg "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVxyOjz48API"
      },
      "source": [
        "NB: In most cases it's much easier to use a \"transfer learning\" trick, rather than perform full training from the scratch. For that, we use existing well-trained model as a starter, and \"finetune\" (uptrain) it with our data. This works pretty well, even if our dataset is very different from the original model. \n",
        "\n",
        "So here is a faster way to train our GAN (presuming we have full trained model `train/ffhq-256.pkl` already):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "z3kwDOh88APJ"
      },
      "outputs": [],
      "source": [
        "#@title Finetune training\n",
        "%cd $work_dir\n",
        "dataset = 'test' #@param {type:\"string\"}\n",
        "resume_pkl = 'train/002-test-512-auto-gf_bnc' #@param {type:\"string\"}\n",
        "kimg = 1000 #@param {type:\"integer\"}\n",
        "data_dir = os.path.join(work_dir, 'data', dataset)\n",
        "\n",
        "%run src/train.py --data $data_dir --resume $resume_pkl --kimg $kimg "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Njelbgu8APJ"
      },
      "source": [
        "## Generation\n",
        "\n",
        "Let's produce some imagery from the original cat model (get it [here](https://nvlabs-fi-cdn.nvidia.com/stylegan2/networks/stylegan2-cat-config-f.pkl) and put onto Google drive within our working directory).  \n",
        "Generated results are saved as sequences and videos (by default, under `_out` directory).  \n",
        "More cool models can be found [here](https://github.com/justinpinkney/awesome-pretrained-stylegan2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9S73oknl8wLU"
      },
      "outputs": [],
      "source": [
        "#@title ### Generator setup\n",
        "!cd $work_dir\n",
        "\n",
        "output = '_out/cats' #@param {type:\"string\"}\n",
        "\n",
        "frames = 50 #@param {type:\"integer\"}\n",
        "frame_step = 10 #@param {type:\"integer\"}\n",
        "timeframe = '%d-%d' % (frames, frame_step)\n",
        "\n",
        "cubic_smooth = True #@param {type:\"boolean\"}\n",
        "gauss_smooth = False #@param {type:\"boolean\"}\n",
        "cubic_smooth = '--cubic ' if cubic_smooth else ''\n",
        "gauss_smooth = '--gauss ' if gauss_smooth else ''\n",
        "smooth = cubic_smooth + gauss_smooth\n",
        "\n",
        "save_lat = False #@param {type:\"boolean\"}\n",
        "save_lat = '--save_lat ' if save_lat else ''\n",
        "\n",
        "seed = 0 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Select model from the dropdown below:\n",
        "model_select(work_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlzqD3DEGzIH"
      },
      "source": [
        "> This means loading the model, and producing 50 frames, interpolating between random latent (`z`) space keypoints, with a step of 10 frames between keypoints. \n",
        "`save_lat` option = save all traversed dlatent (`w`) points as Numpy array in `*.npy` file (useful for further curating). `cubic` option changes linear interpolation to cubic for smoother animation; `gauss` provides additional smoothing. Set `seed` value to produce repeatable results (0 = random)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oBHD0n0i8APJ"
      },
      "outputs": [],
      "source": [
        "#@title ### Native generation\n",
        "%cd $work_dir\n",
        "%run src/_genSGAN2.py --model $model_pkl --out_dir $output --frames $timeframe $smooth $save_lat --seed $seed\n",
        "ipython_display(ImageSequenceClip(img_list(output), fps=25), center=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GwoOBOcR8APK"
      },
      "outputs": [],
      "source": [
        "#@title ### Custom size generation\n",
        "\n",
        "sizeX = 400 #@param {type:\"integer\"} \n",
        "sizeY = 300 #@param {type:\"integer\"}\n",
        "size = '%d-%d' % (sizeX, sizeY)\n",
        "scaling = 'pad' #@param ['pad', 'padside', 'symm', 'symmside']\n",
        "\n",
        "%cd $work_dir\n",
        "%run src/_genSGAN2.py --model $model --out_dir $output --frames $timeframe --size $size --scale_type $scaling  $smooth $save_lat --seed $seed\n",
        "ipython_display(ImageSequenceClip(img_list(output), fps=25), center=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cOGVIJt18APL"
      },
      "outputs": [],
      "source": [
        "#@title ### Multi-latent  generation\n",
        "\n",
        "sizeX = 768 #@param {type:\"integer\"} \n",
        "sizeY = 256 #@param {type:\"integer\"}\n",
        "size = '%d-%d' % (sizeX, sizeY)\n",
        "scaling = 'pad' #@param ['pad', 'padside', 'symm', 'symmside']\n",
        "\n",
        "split_X =  3#@param {type:\"integer\"} \n",
        "split_Y =  1#@param {type:\"integer\"}\n",
        "split = '%d-%d' % (split_X, split_Y)\n",
        "splitfine = 0. #@param {type:\"number\"}\n",
        "\n",
        "%cd $work_dir\n",
        "%run src/_genSGAN2.py --model $model --out_dir $output --frames $timeframe --size $size --scale_type $scaling -n $split --splitfine $splitfine $smooth --seed $seed\n",
        "ipython_display(ImageSequenceClip(img_list(output), fps=25), center=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ3zGyFy8APL"
      },
      "source": [
        "> Here we get animated composition of 3 independent frames, blended together horizontally.  \n",
        "`splitfine` controls boundary fineness (0 = smoothest/default, higher => thinner).  \n",
        "\n",
        "Instead of frame splitting, we can load external mask from b/w image file (or folder with image sequence):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zB0-VZ798APL"
      },
      "outputs": [],
      "source": [
        "#@title ### Masked  generation\n",
        "\n",
        "sizeX = 400 #@param {type:\"integer\"} \n",
        "sizeY = 300 #@param {type:\"integer\"}\n",
        "size = '%d-%d' % (sizeX, sizeY)\n",
        "\n",
        "lat_mask = '_in/mask.jpg' #@param {type:\"string\"} \n",
        "\n",
        "%cd $work_dir\n",
        "%run src/_genSGAN2.py --model $model --out_dir $output --frames $timeframe --size $size --latmask $lat_mask  $smooth --seed $seed\n",
        "ipython_display(ImageSequenceClip(img_list(output), fps=25), center=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWUJDcGW8APM"
      },
      "source": [
        "`digress` adds some funky displacements by tweaking initial constant layer.  \n",
        "`truncation` controls variety, as usual  (0 = boring, >1 = weird). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tITi-ILU8APM"
      },
      "outputs": [],
      "source": [
        "#@title ### Other tricks\n",
        "\n",
        "sizeX = 400 #@param {type:\"integer\"} \n",
        "sizeY = 300 #@param {type:\"integer\"}\n",
        "size = '%d-%d' % (sizeX, sizeY)\n",
        "\n",
        "digress =  2#@param {type:\"number\"} \n",
        "truncation =  1.5#@param {type:\"number\"} \n",
        "\n",
        "%cd $work_dir\n",
        "%run src/_genSGAN2.py --model $model --out_dir $output --frames $timeframe --size $size --digress $digress --trunc $truncation $smooth --seed $seed\n",
        "ipython_display(ImageSequenceClip(img_list(output), fps=25), center=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLBZAOSi8APM"
      },
      "source": [
        "## Latent space exploration\n",
        "\n",
        "For these experiments download [FFHQ model](https://nvlabs-fi-cdn.nvidia.com/stylegan2/networks/stylegan2-ffhq-config-f.pkl) and save to `models` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VB7ujwkD8APM"
      },
      "outputs": [],
      "source": [
        "#@title ### Generator setup\n",
        "!cd $work_dir\n",
        "\n",
        "output = '_out/ffhq' #@param {type:\"string\"}\n",
        "\n",
        "frames = 50 #@param {type:\"integer\"}\n",
        "frame_step = 10 #@param {type:\"integer\"}\n",
        "timeframe = '%d-%d' % (frames, frame_step)\n",
        "\n",
        "cubic_smooth = True #@param {type:\"boolean\"}\n",
        "gauss_smooth = False #@param {type:\"boolean\"}\n",
        "cubic_smooth = '--cubic ' if cubic_smooth else ''\n",
        "gauss_smooth = '--gauss ' if gauss_smooth else ''\n",
        "smooth = cubic_smooth + gauss_smooth\n",
        "\n",
        "save_lat = False #@param {type:\"boolean\"}\n",
        "save_lat = '--save_lat ' if save_lat else ''\n",
        "\n",
        "#@markdown Select model from the dropdown list below:\n",
        "model_select(work_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIbPEUyI8APN"
      },
      "source": [
        "Project external images onto the model dlatent `w` space, saving points as Numpy arrays in `*.npy` files. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BJx9ws7n8APN"
      },
      "outputs": [],
      "source": [
        "#@title ### Images projection\n",
        "\n",
        "image_dir = '_in/photo' #@param {type:\"string\"} \n",
        "out_dir = '_out/proj' #@param {type:\"string\"} \n",
        "steps =  1000#@param {type:\"integer\"} \n",
        "\n",
        "%cd $work_dir\n",
        "%run src/projector.py --model $model_pkl --in_dir _in/photo --out_dir _out/proj --steps $steps\n",
        "\n",
        "from src.util.utilgan import img_list\n",
        "images = img_list(out_dir, subdir=True)\n",
        "images = [f for f in images if 'target.jpg' not in f]\n",
        "Image(images[0], width=512, height=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6l471qJWsX2"
      },
      "source": [
        "Produce looped animation, interpolating between saved dlatent points (from a file or directory with `*.npy` or `*.npz` files). To select only few frames from a sequence `xxx.npy`, create text file with comma-delimited frame numbers and save it as `xxx.txt` in the same directory (check examples in `_in/dlats`). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SIJJUfAN8APN"
      },
      "outputs": [],
      "source": [
        "#@title ### \"Walk\" between saved dlatent points\n",
        "\n",
        "dlatents = '_in/dlats' #@param {type:\"string\"} \n",
        "out_dir = '_out/ffhq-dlats' #@param {type:\"string\"} \n",
        "\n",
        "%cd $work_dir\n",
        "%run src/_play_dlatents.py --model $model --dlatents $dlatents --out_dir $out_dir --fstep $frame_step $smooth\n",
        "ipython_display(ImageSequenceClip(img_list(out_dir), fps=25), center=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NBBc2CV8APN"
      },
      "source": [
        "\n",
        "\n",
        "We can also load another dlatent point and apply it to higher network layers, effectively \"stylizing\" images with its' fine features.  \n",
        "`digress` and `truncation` are also applicable here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "J84NdtP38APO"
      },
      "outputs": [],
      "source": [
        "#@title ### \"Walk\" between saved points w/tricks\n",
        "\n",
        "dlatents = '_in/dlats' #@param {type:\"string\"} \n",
        "out_dir = '_out/ffhq-dlats' #@param {type:\"string\"} \n",
        "style_dlat = '_in/blonde458.npy' #@param {type:\"string\"} \n",
        "digress =  2#@param {type:\"number\"} \n",
        "truncation =  1.5#@param {type:\"number\"} \n",
        "\n",
        "%cd $work_dir\n",
        "%run src/_play_dlatents.py --model $model --dlatents $dlatents --out_dir $out_dir --fstep $frame_step $smooth --style_dlat $style_dlat --digress $digress --trunc $truncation\n",
        "ipython_display(ImageSequenceClip(img_list(out_dir), fps=25), center=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iykr7uKL8APO"
      },
      "source": [
        "Generate animation by walking from saved dlatent point along feature direction vectors (aging/smiling/etc) one by one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UOToqrX68APO",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#@title ### \"Walk\" along feature directions\n",
        "\n",
        "base_lat = '_in/blonde458.npy' #@param {type:\"string\"} \n",
        "vectors = '_in/vectors_ffhq' #@param {type:\"string\"} \n",
        "out_dir = '_out/ffhq_looks' #@param {type:\"string\"} \n",
        "\n",
        "%cd $work_dir\n",
        "%run src/_play_vectors.py --model $model_pkl --base_lat $base_lat --vector_dir $vectors --out_dir $out_dir --fstep $frame_step\n",
        "ipython_display(ImageSequenceClip(img_list(out_dir), fps=25), center=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN_82CUzLWdL"
      },
      "source": [
        "> Try discovering more such vectors:\n",
        "> * https://github.com/genforce/sefa\n",
        "> * https://github.com/harskish/ganspace"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Riyadh StyleGAN2a_colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}